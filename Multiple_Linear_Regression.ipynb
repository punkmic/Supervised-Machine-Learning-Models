{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple Linear Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNt9ITbInLSE1Z4r5dTqqoE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punkmic/Supervised-Machine-Learning-Models/blob/master/Multiple_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Goal**\n",
        "\n",
        "Build a multiple linear regression model\n"
      ],
      "metadata": {
        "id": "oi-dS_Rfjadj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0kEJowAwjQzh"
      },
      "outputs": [],
      "source": [
        "import copy, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=2)  # reduced display precision on numpy arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **We will use this table as out dataset**\n",
        "\n",
        "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
        "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
        "| 2104            | 5                   | 1                | 45           | 460           |  \n",
        "| 1416            | 3                   | 2                | 40           | 232           |  \n",
        "| 852             | 2                   | 1                | 35           | 178           |  "
      ],
      "metadata": {
        "id": "nbXH-NtAkgjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
        "y_train = np.array([460, 232, 178])"
      ],
      "metadata": {
        "id": "Ewyrja8qkokX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Init Parameters w and b**"
      ],
      "metadata": {
        "id": "lC_3NxLapt2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b_init = 785.1811367994083\n",
        "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])"
      ],
      "metadata": {
        "id": "ZWdm0kvNpxtC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Single prediction element by element**"
      ],
      "metadata": {
        "id": "KecY9jj98KV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def predict(x, w, b):\n",
        "  p = np.dot(x, w) + b\n",
        "  return p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKCoLJtS8U4n",
        "outputId": "c4a22978-9214-4b7d-9199-ea138365a4b6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 10.5 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "x_vec = X_train[0, :] # get first row of matrix\n",
        "f_wb = predict(x_vec, w_init, b_init)\n",
        "print(f\"Prediction: {f_wb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qHbZ0DV9qH-",
        "outputId": "0bcf6479-527b-4d9d-f13e-255d0acd3a2d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 459.9999976194083\n",
            "CPU times: user 2.31 ms, sys: 127 µs, total: 2.44 ms\n",
            "Wall time: 3.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compute cost**"
      ],
      "metadata": {
        "id": "8pvwB84hAU6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y , w, b):\n",
        "  m = X.shape[0]\n",
        "  cost = 0\n",
        "  for i in range(m):\n",
        "    f_wb_i = np.dot(X[i], w) + b\n",
        "    cost = cost + (f_wb_i - y[i])**2\n",
        "  cost = cost / (2 * m)\n",
        "  return cost"
      ],
      "metadata": {
        "id": "V6la1fnDATn4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and display cost using our pre-chosen optimal parameters. \n",
        "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
        "print(f'Cost at optimal w : {cost}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy_ApNhEBaCV",
        "outputId": "47711902-6902-4666-b934-f048d18dc29c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost at optimal w : 1.5578904428966628e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compute gradient**"
      ],
      "metadata": {
        "id": "883oqDFkDxLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b): \n",
        "    m,n = X.shape           #(number of examples, number of features)\n",
        "    dj_dw = np.zeros((n,))\n",
        "    dj_db = 0.\n",
        "\n",
        "    for i in range(m):                             \n",
        "        err = (np.dot(X[i], w) + b) - y[i]   \n",
        "        for j in range(n):                         \n",
        "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
        "        dj_db = dj_db + err                        \n",
        "    dj_dw = dj_dw / m                                \n",
        "    dj_db = dj_db / m                                \n",
        "        \n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "7ZOBAlFeDzQw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and display gradient \n",
        "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
        "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
        "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aNzywMFFI6g",
        "outputId": "1a810964-6cc4-43b6-8903-a78126edd52e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dj_db at initial w,b: -1.6739251501955248e-06\n",
            "dj_dw at initial w,b: \n",
            " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient Descent**"
      ],
      "metadata": {
        "id": "9XQrLI6JFV-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
        "    b = b_in\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w = w - alpha * dj_dw               ##None\n",
        "        b = b - alpha * dj_db               ##None\n",
        "      \n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion \n",
        "            J_history.append( cost_function(X, y, w, b))\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters / 10) == 0:\n",
        "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
        "        \n",
        "    return w, b, J_history #return final w,b and J history for graphing"
      ],
      "metadata": {
        "id": "fQqyWLYhFYOl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test our model**"
      ],
      "metadata": {
        "id": "4JnnShepIFFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize parameters\n",
        "initial_w = np.zeros_like(w_init)\n",
        "initial_b = 0.\n",
        "# some gradient descent settings\n",
        "iterations = 1000\n",
        "alpha = 5.0e-7\n",
        "# run gradient descent \n",
        "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
        "                                                    compute_cost, compute_gradient, \n",
        "                                                    alpha, iterations)\n",
        "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
        "m,_ = X_train.shape\n",
        "for i in range(m):\n",
        "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ66CI9rH8Qq",
        "outputId": "b2746e33-5189-4cc9-9e54-b6d0c2f3f700"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration    0: Cost  2529.46   \n",
            "Iteration  100: Cost   695.99   \n",
            "Iteration  200: Cost   694.92   \n",
            "Iteration  300: Cost   693.86   \n",
            "Iteration  400: Cost   692.81   \n",
            "Iteration  500: Cost   691.77   \n",
            "Iteration  600: Cost   690.73   \n",
            "Iteration  700: Cost   689.71   \n",
            "Iteration  800: Cost   688.70   \n",
            "Iteration  900: Cost   687.69   \n",
            "b,w found by gradient descent: -0.00,[ 0.2   0.   -0.01 -0.07] \n",
            "prediction: 426.19, target value: 460\n",
            "prediction: 286.17, target value: 232\n",
            "prediction: 171.47, target value: 178\n"
          ]
        }
      ]
    }
  ]
}